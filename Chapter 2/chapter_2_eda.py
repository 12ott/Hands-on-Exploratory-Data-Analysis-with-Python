# -*- coding: utf-8 -*-
"""Chapter 2 EDA.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JeaLS-MehkamRYyF0bs6Gu252t5iP9LW

# Visual Aids for Exploratory Data Analysis

In this chapter we are going to learn about different visualization techniques using simpler data set.
"""

!pip install faker 
!pip install radar

from faker import Faker
fake = Faker()

import datetime
import math
import pandas as pd
import random 
import radar

import datetime
import math
import pandas as pd
import random 
import radar 
from faker import Faker
fake = Faker()

def generateData(n):
  listdata = []
  start = datetime.datetime(2019, 8, 1)
  end = datetime.datetime(2019, 8, 30)
  delta = end - start
  for _ in range(n):
    date = radar.random_datetime(start='2019-08-1', stop='2019-08-30').strftime("%Y-%m-%d")
    price = round(random.uniform(900, 1000), 4)
    listdata.append([date, price])
  df = pd.DataFrame(listdata, columns = ['Date', 'Price'])
  df['Date'] = pd.to_datetime(df['Date'], format='%Y-%m-%d')
  df = df.groupby(by='Date').mean()

  return df

"""# Line Chart

Do you remember what is continous variable and what is discrete variable? If not, get a sneak peak into chapter 1, _fundamentals of EDA_. Back to the main topic, line chart is used to illustrate the relationship between two or more continous variables. 

We are going to use `matplotlib` library and Stock price data for plotting time series line. First of all, let us understand the data set. I have created a function using `faker` Python library to generate the dataset. The simplest possible dataset you can assume with just two columns. The first column is `Date` and the second columin is `Price` indicating the Stock Price at that date. 

Let us generate the dataset by calling the helper method. In addition to this, I have saved the CSV file. You can optionally load the CSV file using Pandas (`read_csv`) library and proceed with visualization.
"""

df = generateData(50)
df.head(10)

df.to_csv(r'stock.csv')

"""## Steps Involved 

1.   Load the dataset and prepare the dataset. We will learn more how we can prepare the data in the chapter 4, data transformation. For this exercise, all the data are pre-processed. 
2.   Import the matplotlib library. It can be done simply by:

```
import matplotlib.pyplot as plt
```
3. Plot the graph. 

```
plt.plot(df)
```
4. Display on the screen. 

```
plt.show()
```
"""

import matplotlib.pyplot as plt

plt.rcParams['figure.figsize'] = (14, 10)
plt.plot(df)

"""In the example above, we assume the data is available in the form of files. In real life scenaior, the data is mostly avaialble in CSV, JSON, Excel or XML formats and mostly dissiminated through some standard API. For this series, I assume you are already familiar with `Pandas` and how to read different types of files. If not, its time to revise `Pandas`, again. Refer to `Pandas` documentation for further details http://pandas-datareader.readthedocs.io/en/latest/.

# Bar Chart (Plots)

Well, this is one of the most common type of visualization that everyone must have encountered. Bars can be drawn horizontally or vertically to represent categorical variable. 

Bar charts are frequently utilized to distinguish objects between distinct collections to track variations over time. In the most cases, **bar charts** are very conventient when the changes are larger. In order to learn bar chart, let us assume a pharmacy in Norway keep tracks of number of **Zoloft** sold every month. Zoloft is a medicine prescribed to patients suffering from depression. We can use the Python library `calender` to keep track of months of year (1 to 12) corresponding from January to December.
"""

# Let us import the required libraries
import numpy as np
import calendar
import matplotlib.pyplot as plt

# Step 1: Set up the data. Remember range stoping parameter is exclusive. Meaning if you generate range from (1, 13), the last item 13 is not included. 
months = list(range(1, 13))
sold_quantity = [round(random.uniform(100, 200)) for x in range(1, 13)]

# Step 2: Specify the layout of the figure and allocate space. 
figure, axis = plt.subplots()

# Step 3: In the X-axis, we would like to display the name of the months. 
plt.xticks(months, calendar.month_name[1:13], rotation=20)

# Step 4: Plot the graph
plot = axis.bar(months, sold_quantity)

# Step 5: This step can be optinal depending upon if you are interested in displaying the data vaue on the head of the bar. 
# It visually gives more meaning to show actual number of sold iteams on the bar itself. 
for rectangle in plot:
  height = rectangle.get_height()
  axis.text(rectangle.get_x() + rectangle.get_width() /2., 1.002 * height, '%d' % int(height), ha='center', va = 'bottom')

# Step 6: Display the graph on the screen. 
plt.show()

"""Here are important observations from above visualizations. 

1.  `months` and `sold_quantity` are Python lists reprsenting the number of **Zoloft** sold every months. 
2.   We are using `subplots()` method in the code above. Why? Well, it provides a way to define the layout of the figure in terms of the number of graphs and allows ways to organize them. Still confused? Don't worry, we will be using subplots plenty of times in this course. Moreover, if you need quick reference, PACKT has several books explaining `maptplotlib`. Here are some of the most interesting reads[1, 2, 3]. 
3. Step 3 using `plt.xticks()` that allows us to change X-asis tickers from 1 to 12 whereas, `calender.months[1:13]` changes this numerical format into corresponding months from the `calender` Python library. 
4. Step 4 actually prints the bar with `months` and quantity sold. 
5. `ax.text()` within `for` loop annotates each bar with its corresponding values. How it does might be interesting. The way we plotted these values are, we get X and Y coordinates and then add `bar_width/2` to the X coordinates with 1.0002 height being the Y co-ordinate. Then using the `va` and `ha` arguments we align the text centrally over the bar. 
6. Step 6 actually displays the grap on the screen.

As mentioned in the introduction of Bar chart, we phrased bars can be either horizontally or vertically. Let us change into horizontal format. All the codes remains same except, `plt.xticks` changes to `plt.yticks()` and `plt.bar()` changes to `plt.barh()`. I assume, it is self explanatory. In addition to this, placing the exact data values is a bit tricky and requires few iterations of hit and trial methods to place them perfectly. But let us see them in action.
"""

# Step 1: Set up the data. Remember range stoping parameter is exclusive. Meaning if you generate range from (1, 13), the last item 13 is not included. 
months = list(range(1, 13))
sold_quantity = [round(random.uniform(100, 200)) for x in range(1, 13)]

# Step 2: Specify the layout of the figure and allocate space. 
figure, axis = plt.subplots()

# Step 3: In the X-axis, we would like to display the name of the months. 
plt.yticks(months, calendar.month_name[1:13], rotation=20)

# Step 4: Plot the graph
plot = axis.barh(months, sold_quantity)

# Step 5: This step can be optinal depending upon if you are interested in displaying the data vaue on the head of the bar. 
# It visually gives more meaning to show actual number of sold iteams on the bar itself. 
for rectangle in plot:
  width = rectangle.get_width()
  axis.text(width + 2.5, rectangle.get_y() + 0.38, '%d' % int(width), ha='center', va = 'bottom')

# Step 6: Display the graph on the screen. 
plt.show()

"""# Scatter Plots

They are also recognized by the others names such as `scatter graph`, `scatter chart`, `scattergram`, and `scatter diagram`. It use Cartesian coordinates system to display values for typically two variables for a set of data. 

**When to use Scatter Plot?** 
Scatter plot can be constructed in following two situations:

-  When one continous variable is dependent on another variable which is under the control of the observer.
- When both continuous variables are independent. 

Note here are two important concepts. **Independent variable** and **dependent variable**. In statistical modeling or mathematical modeling, the values gained by dependent variables rely on the values gained by independent variables. The *dependent variable* is the outcome variable being studied. The independent variables are also referred to as **regressors**. The takeaway message here is, scatter plots are utilized when we need to show the relationship between two variables and hence are sometime also referred to as **correlation plots**. We will dig into more details about correlation in the chapter 10, *correlation*.

Either you are an expert data scientiest or a beginner computer science student, no doubt you have encountered one or other forms of scatter plots before. These plots are highly powerful tools for visualization depsite its simplicity. The main reason is it has a lot of options, representataional powers, design choices and is flexible enough to represent graph in attractive ways. 

Some examples in which scatter plots can be best fit:

*   Research studies have sucessfully establishted that the number of hours of sleep required by a person depends on the age of the person. 
*   Average income for adults are based on the number of years of education. 

Let us take the first case and generate some data. I am going to use a helper function to generate a dataset that includes sleep duration recommendation based on the age. The recommended data is taken from here: https://www.sleepfoundation.org/press-release/national-sleep-foundation-recommends-new-sleep-times.
"""

age = list(range(0, 65))
sleep = []

classBless = ['newborns(0-3)', 'infants(4-11)', 'toddlers(12-24)', 'preschoolers(36-60)', 'school-aged-children(72-156)', 'teenagers(168-204)', 'young-adults(216-300)','adults(312-768)', 'older-adults(>=780)']
headers_cols = ['age','min_recommended', 'max_recommended', 'may_be_appropriate_min', 'may_be_appropriate_max', 'min_not_recommended', 'max_not_recommended'] 

# Newborn (0-3)
for i in range(0, 4):
  min_recommended = 14
  max_recommended = 17
  may_be_appropriate_min = 11
  may_be_appropriate_max = 13
  min_not_recommended = 11
  max_not_recommended = 19
  sleep.append([i, min_recommended, max_recommended, may_be_appropriate_min, may_be_appropriate_max, min_not_recommended, max_not_recommended])

# infants(4-11)
for i in range(4, 12):
  min_recommended = 12
  max_recommended = 15
  may_be_appropriate_min = 10
  may_be_appropriate_max = 11
  min_not_recommended = 10
  max_not_recommended = 18
  sleep.append([i, min_recommended, max_recommended, may_be_appropriate_min, may_be_appropriate_max, min_not_recommended, max_not_recommended])

# toddlers(12-24)
for i in range(12, 25):
  min_recommended = 11
  max_recommended = 14
  may_be_appropriate_min = 9
  may_be_appropriate_max = 10
  min_not_recommended = 9
  max_not_recommended = 16
  sleep.append([i, min_recommended, max_recommended, may_be_appropriate_min, may_be_appropriate_max, min_not_recommended, max_not_recommended])

# preschoolers(36-60)
for i in range(36, 61):
  min_recommended = 10
  max_recommended = 13
  may_be_appropriate_min = 8
  may_be_appropriate_max = 9
  min_not_recommended = 8
  max_not_recommended = 14
  sleep.append([i, min_recommended, max_recommended, may_be_appropriate_min, may_be_appropriate_max, min_not_recommended, max_not_recommended])

# school-aged-children(72-156)
for i in range(72, 157):
  min_recommended = 9
  max_recommended = 11
  may_be_appropriate_min = 7
  may_be_appropriate_max = 8
  min_not_recommended = 7
  max_not_recommended = 12
  sleep.append([i, min_recommended, max_recommended, may_be_appropriate_min, may_be_appropriate_max, min_not_recommended, max_not_recommended])

# teenagers(168-204)
for i in range(168, 204):
  min_recommended = 8
  max_recommended = 10
  may_be_appropriate_min = 7
  may_be_appropriate_max = 11
  min_not_recommended = 7
  max_not_recommended = 11
  sleep.append([i, min_recommended, max_recommended, may_be_appropriate_min, may_be_appropriate_max, min_not_recommended, max_not_recommended])

# young-adults(216-300) 
for i in range(216, 301):
  min_recommended = 7
  max_recommended = 9
  may_be_appropriate_min = 6
  may_be_appropriate_max = 11
  min_not_recommended = 6
  max_not_recommended = 11
  sleep.append([i, min_recommended, max_recommended, may_be_appropriate_min, may_be_appropriate_max, min_not_recommended, max_not_recommended])

# adults(312-768) 
for i in range(312, 769):
  min_recommended = 7
  max_recommended = 9
  may_be_appropriate_min = 6
  may_be_appropriate_max = 10
  min_not_recommended = 6
  max_not_recommended = 10
  sleep.append([i, min_recommended, max_recommended, may_be_appropriate_min, may_be_appropriate_max, min_not_recommended, max_not_recommended])

# older-adults(>=780)
for i in range(769, 780):
  min_recommended = 7
  max_recommended = 8
  may_be_appropriate_min = 5
  may_be_appropriate_max = 6
  min_not_recommended = 5
  max_not_recommended = 9
  sleep.append([i, min_recommended, max_recommended, may_be_appropriate_min, may_be_appropriate_max, min_not_recommended, max_not_recommended])

sleepDf = pd.DataFrame(sleep, columns=headers_cols)
sleepDf.head(10)
sleepDf.to_csv(r'sleep_vs_age.csv')

"""I am using the helper method above to generate the dataset. The same dataset can be found in the form of CSV file in the GitHub repository. Instead of using the helper code above, feel free to use `Pandas` to read CSV file and generate scatter plot."""

import seaborn as sns
import matplotlib.pyplot as plt
sns.set()

# A regular scatter plot
plt.scatter(x=sleepDf["age"]/12., y=sleepDf["min_recommended"])
plt.scatter(x=sleepDf["age"]/12., y=sleepDf['max_recommended'])
plt.xlabel('Age of person in Years')
plt.ylabel('Total hours of sleep required')
plt.show()

"""That was not so difficult, was it? Let us see if we can interpret the graph we got. You can explicity see the total hours of sleep required by a person is higher initially and gradually lowers down as ones age progresses. The resulting graph looks interpretable but due to lack of continous line, somehow the results are not self-explanatory. Are you thinking what, I am thinking? Of course, let us fit, a line chart and see if that explains the results in more obvious way."""

# Line plot
plt.plot(sleepDf['age']/12., sleepDf['min_recommended'], 'g--')
plt.plot(sleepDf['age']/12., sleepDf['max_recommended'], 'r--')
plt.xlabel('Age of person in Years')
plt.ylabel('Total hours of sleep required')
plt.show()

"""And probably it does. Do you agree? From the graph it seems clear with two lines declining as the age is increasing. It shows the new borns between 0 to 3 months age require at least 14-17 hours of sleep everyday. Meanwhile, the adults and older adults require 7 to 9 hours of sleep everyday. Is your sleeping pattern within this range?

Let us take another example of scatter plot using the most popular dataset used in the data science - `Iris dataset`. The dataset introduced by Ronald Fisher in 1936 is widely adopted by several bloggers, books, articles and research papers to demonstrate various aspects of data science and data mining. The dataset holds 50 examples each of three different species of Iris named Setosa, Virginica, and Versicolor. Each example has 4 different attributes: petal length, petal width, sepal length, and sepal width. 

The dataset can be loaded in several ways. Here we are using `seaborn` to load the dataset.
"""

import seaborn as sns
import matplotlib.pyplot as plt

# Set some default parameters of matplotlib
plt.rcParams['figure.figsize'] = (8, 6)
plt.rcParams['figure.dpi'] = 150

# Use style froms seaborn. Try to comment the next line and see the difference in graph
sns.set()

# Load the Iris dataset
df = sns.load_dataset('iris')

df['species'] =  df['species'].map({'setosa': 0, "versicolor": 1, "virginica": 2})

# A regular scatter plot
plt.scatter(x=df["sepal_length"], y=df["sepal_width"], c = df.species)

# Create labels for axises
plt.xlabel('Sepal Length')
plt.ylabel('Sepal Width')

# Display the plot on the screen
plt.show()

"""Do you find this graph more informative? I would assume, most of you agree with the fact that, you can clearly see three different types of points and somehow there is three different clusters. Although, it is not clear which color represents which species of Iris flower. We are going to learn how to create legends in subsequent sections.

# Bubble plot

Bubble plot is a manisfestation of the scatter plot where each data points on the graph is shown as a bubble. Each bubbles can be illustrated with a different color, size and appearance. 

Let us continue using `Iris` dataset to get bubble plot. Here the important thing to notice is we are still going to use `plt.scatter` method to draw bubbble chart too.
"""

# Load the Iris dataset
df = sns.load_dataset('iris')

df['species'] =  df['species'].map({'setosa': 0, "versicolor": 1, "virginica": 2})

# Create bubble plot
plt.scatter(df.petal_length, df.petal_width,
            s=50*df.petal_length*df.petal_width, 
            c=df.species,
            alpha=0.3
            )

# Create labels for axises
plt.xlabel('Petal Length')
plt.ylabel('Petal Width')
plt.show()

"""# Scatter plot using seaborn

Scatter plot also be generated using `seaborn` library. Seaborn makes the graph visually better. We can illustrate the relationship between `X` and `Y` for distinct subsets of the data by utilizing the `size`, `style` and `hue` parameter of scatterplot in seaborn. 

Get more detailed information about its parameter from its documentation website: https://seaborn.pydata.org/generated/seaborn.scatterplot.html.
"""

df = sns.load_dataset('iris')

df['species'] =  df['species'].map({'setosa': 0, "versicolor": 1, "virginica": 2})
sns.scatterplot(x=df["sepal_length"], y=df["sepal_width"], hue=df.species, data=df)

"""# Area plot and Stacked Plot 

Stacked plot owns its name to the fact that, it represents area under a line plot and several such plots can be stacked on to top of one another giving a feeling of stack. Stacked plot can be useful when we want to visualize the **cummulative effect** of multple variables being plotted on the Y axis. 

In order to simplify understanding, consider area plot as the line plot that shows the area covered by filling with some color.
"""

houseLoanMortage = [9000, 9000, 8000, 9000, 
                    8000, 9000, 9000, 9000, 
                    9000, 8000, 9000, 9000]
utilitiesBills = [4218, 4218, 4218, 4218,
                  4218, 4218, 4219, 2218, 
                  3218, 4233, 3000, 3000]
transportation = [782, 900, 732, 892,
                  334, 222, 300, 800, 
                  900, 582, 596, 222]
carMortage = [700, 701, 702, 703, 
              704, 705, 706, 707, 
              708, 709, 710, 711]


import matplotlib.pyplot as plt
import seaborn as sns

months= [x for x in range(1,13)]

sns.set()
plt.plot([],[], color='sandybrown', label='houseLoanMortage')
plt.plot([],[], color='tan', label='utilitiesBills')
plt.plot([],[], color='bisque', label='transportation')
plt.plot([],[], color='darkcyan', label='carMortage')

plt.stackplot(months, houseLoanMortage, utilitiesBills, transportation, carMortage, colors=['sandybrown', 'tan', 'bisque', 'darkcyan'])
plt.legend()

plt.title('Household Expenses')
plt.xlabel('Months of the year')
plt.ylabel('Cost')

plt.show()

"""# Pie chart

This is one of the interesting type of data visualization graph. I am arguing as interesting not because it has higher preferences or higher illustrative capacity but because it is one of the most argued type of visualization in the reasearch. 

A paper by Ian Spence in 2005, "No Humble Pie: The Origins and Usage of a Statistical Chart" argues the pie chart fails to appear most of the experts. Despite similar such studies, people have still chosen to use pie chart. There are several agruments given by communities for not adhering to pie chart. One of the arguments is, human beings are naturally not good at distinguising differences in slices of circle at a glance. It is very unlikely to compare similar slices from other slices in the pie charts. Another argument is, people tend to overestimate the size of obtuse angle. Similarly, people seems to underestimate the size of acute angles. 

Having critized heavily, let us also discover some postive angles. One counter agrument is, if pie chart is not communicative, why does this still persist? The main reason is people love circles. Moreover, the purpose of the pie chart is to communicate proportions and it is widely accepted by all people. Enough said, let us use Pokemon dataset to draw piechart.

There are two ways in which you can load the data. First, directly from the GitHub URL. Secondly, download the dataset from the GitHub and reference it from your local machine by providing correct path. In either case, you can use `read_csv` method from Pandas library. Check the snippet below.
"""

# Create URL to JSON file (alternatively this can be a filepath)
url = 'https://raw.githubusercontent.com/hmcuesta/PDA_Book/master/Chapter3/pokemonByType.csv'

# Load the first sheet of the JSON file into a data frame
pokemon = pd.read_csv(url, index_col='type')

pokemon

import matplotlib.pyplot as plt

plt.pie(pokemon['amount'], labels=pokemon.index, shadow=False, startangle=90, autopct='%1.1f%%',)
plt.axis('equal') 
plt.show()

"""Do you know you can directly use Pandas library to create pie chart? Check the one liner below."""

pokemon.plot.pie(y="amount", figsize=(20, 10))

"""This is why Python is said to be commedian. Do you know why? Because, it has a lot of one liners. Pretty true right?

# Table Chart

A table chart combines both a bar chart and a table. In order to understand the table chart let us consider the following data set. Consider standard LED bulbs that comes in different watts. The standard Philips LED bulb comes in 4.5 watt, 6 watt, 7 watt, 8.5 watt, 9.5 watt, 13.5 watt, and 15 watt. And let us assume two categorical variables year and light bulb watts and a numeric variable, that is the number of units sold in a particular year.
"""

# Years under consideration
years = ["2010", "2011", "2012", "2013", "2014"]

# Available watt
columns = ['4.5W', '6.0W', '7.0W','8.5W','9.5W','13.5W','15W']
unitsSold = [
             [65, 141, 88, 111, 104, 71, 99],
             [85, 142, 89, 112, 103, 73, 98],
             [75, 143, 90, 113, 89, 75, 93],
             [65, 144, 91, 114, 90, 77, 92],
             [55, 145, 92, 115, 88, 79, 93],
            ]

# Define the range and scale for the y axis
values = np.arange(0, 600, 100)

# Commented out IPython magic to ensure Python compatibility.
colors = plt.cm.OrRd(np.linspace(0, 0.7, len(years)))
index = np.arange(len(columns)) + 0.3
bar_width = 0.7

y_offset = np.zeros(len(columns))
fig, ax = plt.subplots()

cell_text = []

n_rows = len(unitsSold)
for row in range(n_rows):
    plot = plt.bar(index, unitsSold[row], bar_width, bottom=y_offset, 
                   color=colors[row])
    y_offset = y_offset + unitsSold[row]
    cell_text.append(['%1.1f' % (x) for x in y_offset])
    i=0
# Each iteration of this for loop, labels each bar with corresponding value for the given year
    for rect in plot:
        height = rect.get_height()
        ax.text(rect.get_x() + rect.get_width()/2, y_offset[i],'%d' 
#                 % int(y_offset[i]), 
                ha='center', va='bottom')
        i = i+1 

# Add a table to the bottom of the axes
the_table = plt.table(cellText=cell_text, rowLabels=years, 
                rowColours=colors, colLabels=columns, loc='bottom')
plt.ylabel("Units Sold")
plt.xticks([])
plt.title('Number of LED Bulb Sold/Year')
plt.show()

"""# Polar chart

Do you remember polar axis from mathematics class? Well a polar chart is diagram that is plotted on such polar axis. It has coordinates as angle and radius, as opposed to the Cartesian system of X and Y coordinates. Sometime, it is also referred as spider web plot. Let us see how we can plot an example of Polar chart.
"""

# Let us assume you have 5 courses in your academic year. 
subjects = ["C programming", "Numerical methods", "Operating system", "DBMS", "Computer Networks"]

# And you planned to obtained following grades in each subject
plannedGrade = [90, 95, 92, 68, 68, 90]

# However, after your final examination, this is the grade you got
actualGrade = [75, 89, 89, 80, 80, 75]

"""Having all the dataset ready, let us try to create a polar chart. The first step is to initialize the spider plot. This can be don by setting the figure size and polar projection. This should be clear by now. Note, in the above data set, the list of grades contains an extra entry. This is because it is a circular plot and we need to connect the first point and the last point together to form a circular flow. Hence, we copy the first entry from both list and append at the end of the list. In the above data, the entries 90 and 75 are the first entries of the list respectively."""

# 1. Import required libraries
import numpy as np
import matplotlib.pyplot as plt

# 2. Prepare the data set. 
# 3. Set up theta

theta = np.linspace(0, 2 * np.pi, len(plannedGrade))

# 4. Initialize the plot by figure size and polar projection
plt.figure(figsize = (10,6))
plt.subplot(polar=True)

# 5. Get the grid lines to align with each of the subject names.
(lines,labels) = plt.thetagrids(range(0,360, int(360/len(subjects))),
                                                (subjects))

# 6. We use plot method to plot the graph. And fill the area under it. 
plt.plot(theta, plannedGrade)
plt.fill(theta, plannedGrade, 'b', alpha=0.2)

# 7. Now, we plot the actual grade obtained
plt.plot(theta, actualGrade)

# 8. Finally, we add a legend and a nice comprehensible title to the plot. 
plt.legend(labels=('Planned Grades','Actual Grades'),loc=1)
plt.title("Plan vs Actual grades by Subject")

# 9. Lastly, we show the plot on the screen. 
plt.show()

"""# Histogram

Histogram plots are used to depict the distribution of any continous variable. These types of plots are very popular in statistical analysis. 

Consider the following use cases. A survey created in vocational training session of developers had 100 participants. They had several years of Python programming experience ranging from 0 to 20. The data set is given below:
"""

import numpy as np
import matplotlib.pyplot as plt

# 1. Create data set
yearsOfExperience = np.array([10, 16, 14,  5, 10, 11, 16, 14,  3, 14, 13, 19,  2,  5,  7,  3, 20,
       11, 11, 14,  2, 20, 15, 11,  1, 15, 15, 15,  2,  9, 18,  1, 17, 18,
       13,  9, 20, 13, 17, 13, 15, 17, 10,  2, 11,  8,  5, 19,  2,  4,  9,
       17, 16, 13, 18,  5,  7, 18, 15, 20,  2,  7,  0,  4, 14,  1, 14, 18,
        8, 11, 12,  2,  9,  7, 11,  2,  6, 15,  2, 14, 13,  4,  6, 15,  3,
        6, 10,  2, 11,  0, 18,  0, 13, 16, 18,  5, 14,  7, 14, 18])
yearsOfExperience

plt.figure(figsize = (10,6))

# 2. Plot the distribution of group experience
nbins = 20
n, bins, patches = plt.hist(yearsOfExperience, bins=nbins)

# 3. Add labels to the axis and title
plt.xlabel("Years of experience with Python Programming")
plt.ylabel("Frequency")
plt.title("Distribution of Python programming experience in the vocational training session")

# 4. Draw a green vertical line in the graph at the average experience:
plt.axvline(x=yearsOfExperience.mean(), linewidth=3, color = 'g') 

# 5. Display the plot 
plt.show()

"""Much better right. Now from the figure it is easier to say, the average experience of the participants is around 10 years. Can we somehow improve the graph for better readability? How about, we try to plot the percentage of the sum of all the entries in `yearsOfExperience`. In addition to that, we can also plot normal distribution using the mean and standard deviation of this data to see distribution pattern. Not sure what is normal distribution? I suggest, you go through the references in the first chapter. In a nutshell, normal distribution is also referred to as the Gaussian distribution. The term indicates the probability distribution that is symmetric about the mean, illustrating that data near the average (mean) are most frequent in the occurance than data far from the mean. Enough theory, lets dive into hands-on. 

To plot the distribution, we can add a parameter `density=1` in the `plt.hist` function.
"""

plt.figure(figsize = (10,6))

# 2. Plot the distribution of group experience
nbins = 20
n, bins, patches = plt.hist(yearsOfExperience, bins=nbins, density=1)

# 3. Add labels to the axis and title
plt.xlabel("Years of experience with Python Programming")
plt.ylabel("Frequency")
plt.title("Distribution of Python programming experience in the vocational training session")

# 4. Draw a green vertical line in the graph at the average experience:
plt.axvline(x=yearsOfExperience.mean(), linewidth=3, color = 'g') 

# 5. Compute mean and standard deviation of the dataset.
mu = yearsOfExperience.mean()
sigma = yearsOfExperience.std()

# 6. Adding a best-fit line for normal distribution. 
y = ((1 / (np.sqrt(2 * np.pi) * sigma)) * np.exp(-0.5 * (1 / sigma * (bins - mu))**2))

# 7. Plot the normal distribution
plt.plot(bins, y, '--')

# 8. Display the plot 
plt.show()

"""The plot above illustrates clearly that, it is not following normal distribution. There are many vertical bars which are above and below the best fit for a normal curve.  Wondering where did I get the formula to compute step 6 in the above code. Well, there is a small theory invovled. When I mentioned, normal distribution, we can compute probability density function using Gaussian Distribution function given by `((1 / (np.sqrt(2 * np.pi) * sigma)) * np.exp(-0.5 * (1 / sigma * (bins - mu))**2))`

# Lollipop chart

Lollipop chart can be used to display ranking in the data. It is similar as a ordered bar chart. 

Let us consider the car dataset. It can be found in the second chapter GitHub repo. Alternatively, it can be used from GitHub link directly as mentioned in the code below.
"""

# 1. Read the dataset

carDF = pd.read_csv('https://raw.githubusercontent.com/PacktPublishing/hands-on-exploratory-data-analysis-with-python/master/Chapter%202/cardata.csv')

# 2. Group by manufacturer and take average milage
processedDF = carDF[['cty','manufacturer']].groupby('manufacturer').apply(lambda x: x.mean())

# 3. Sort the values by cty and reset index
processedDF.sort_values('cty', inplace=True)
processedDF.reset_index(inplace=True)

# 4. Plot the graph
fig, ax = plt.subplots(figsize=(16,10), dpi= 80)
ax.vlines(x=processedDF.index, ymin=0, ymax=processedDF.cty, color='firebrick', alpha=0.7, linewidth=2)
ax.scatter(x=processedDF.index, y=processedDF.cty, s=75, color='firebrick', alpha=0.7)

# 5. Annotate Title
ax.set_title('Lollipop Chart for Highway Mileage using car dataset', fontdict={'size':22})

# 6. Anotate labels and xticks, ylim
ax.set_ylabel('Miles Per Gallon')
ax.set_xticks(processedDF.index)
ax.set_xticklabels(processedDF.manufacturer.str.upper(), rotation=65, fontdict={'horizontalalignment': 'right', 'size':12})
ax.set_ylim(0, 30)

# 7. Write the values in the plot
for row in processedDF.itertuples():
    ax.text(row.Index, row.cty+.5, s=round(row.cty, 2), horizontalalignment= 'center', verticalalignment='bottom', fontsize=14)

# 8. Display the plot on the screen
plt.show()

"""# How to choose which chart is best one?

There is no standard that is defined which chart should you choose for visualizing your data. However, there are some guidelines that can help you. Here are some of them:


*   As mentioned in each type of charts above, it is important to understand what type of data you have. If you have continous variable involved, then histogram would be good choice. Similarly, if you want to show ranking ordered bar chart would be good choice and so on. 
*   Choose the chart which effectively conveys the right and relevant meaning of the data without actually distorting the facts. 
* Simplicity is the best. It is considered best to draw simple chart that is comprehensible than sophisticated that requires acquintance of several reports and texts for understanding. 
* Choose diagram that does not overload with information. Our purpose should be to illustrate abstract information in a better way. 

Having said that, let us see if we can generalize some type of categories of charts based on various purposes. 

## Show correlation
- scatter plot 
- Correlogram
- Pairwise plot
- Jittering with stripplot
- Counts plot
- Marginal Histogram
- Scatter plot with line of best fit
- Bubble plot with circling

## Show deviation 
- Area chart
- Diverging bars
- Diverging texts
- Diverging dot plot
- Diverging lollipop plot with markers

## Show distribution
- Histogram for continuous variable
- Histogram for categorical variable
- Density plot
- Categorical plots
- Density curves with histogram
- Population pyramid
- Violin plot
- Joy plot
- Distributed dot plot
- Box plot 

## Show composition
- Waffle chart
- Pie chart
- Tree map
- Bar chart

## Show change
- Time series plot
- Time series with peaks and troughs annotated
- Autocorrelation plot
- Cross correlation plot
- Multiple time series
- Plotting with different scales using secondary Y axis
- Stacked area chart
- Seasonal plot
- Calendar heat map
- Area chart unstacked

## Show groups
- Dendrogram
- Cluster Plot
- Andrews Curve
- Parallel Coordinates

## Show ranking
- Ordered bar chart
- Lollipop chart
- Dot plot
- Slope plot
- Dumbbell plot

# Other libraries to Explore

As aforementioned, visualization of data provides insights that can not be generalized from the data. We have so far seen different types of 2D and 3D visualization techniques using matplotlib and seaborn. Apart from these widely used Python libraries there are other libraries that you can explore. 

- Ploty (https://plot.ly/python/): It is a web-application based toolkit for visualization. Its API for notebook and other applications makes it very powerful to represent 2D and 3D charts. 
- Ggplot (http://ggplot.yhathq.com/): It is a python implementation of the Grammar of the graphics library from R programming language. 
- Altair (https://altair-viz.github.io/): It is built on the top of the powerful Vega-Lite visualization grammar and follows very declarative statistical visualization library techniques. In additiom to that, it has very descriptive and simple API to provide powerful visualization charts.
"""

